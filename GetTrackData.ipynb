{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559d75ea",
   "metadata": {},
   "source": [
    "# Spotify Tracks\n",
    "Objective is to understand characteristics of the best songs. This script interfaces with the \n",
    "spotify API to load track data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2c1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to interact with the system and local environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Requests and encoding packages to interact with Spotify API\n",
    "import base64\n",
    "import requests\n",
    "from urllib.parse import urlencode \n",
    "\n",
    "# Analytics code\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6e27202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_wait(t = 5, duration = 's'):\n",
    "    '''\n",
    "Function pauses script for a random amount of time. It takes two arguments:\n",
    "\n",
    "t: int, gives upper bound of random integer that is generated\n",
    "duration: str, contains values 'short', 's', 'long', 'l' and determines whether the \n",
    "    puase is short (1+random_int/10) or long (random_int)\n",
    "    '''\n",
    "\n",
    "    rt = random.randint(1, 5)\n",
    "    \n",
    "    if duration in ['s', 'short']:\n",
    "        time.sleep(1+rt/10)\n",
    "        \n",
    "    if duration in ['l', 'long']:\n",
    "        time.sleep(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18a551b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env and store values as variables\n",
    "load_dotenv()\n",
    "ClientID = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "ClientSecret = os.getenv('SPOTIFY_CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a64ea201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode credentials and store as headers to pass to request\n",
    "client_cred = f'{ClientID}:{ClientSecret}'\n",
    "client_cred_b64 = base64.b64encode(client_cred.encode())\n",
    "token_headers = {\n",
    "    'Authorization' : f'Basic {client_cred_b64.decode()}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5875c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access token \n",
    "APIKey = requests.post(\n",
    "    url = 'https://accounts.spotify.com/api/token', \n",
    "    data = {'grant_type' : 'client_credentials'},\n",
    "    headers = token_headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a416481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication argument to put into requests\n",
    "auth_header = {\n",
    "    'Authorization' : f\"{APIKey.json()['token_type']} {APIKey.json()['access_token']}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50916d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Script Executed\n"
     ]
    }
   ],
   "source": [
    "# Several different endpoints, can specify which to use with ep\n",
    "# This then becomes part of the url in endpoint\n",
    "ep = 'search'\n",
    "endpoint = 'https://api.spotify.com/v1/'+ep\n",
    "\n",
    "# Search for top hits playlists; takes query (q) and type (artist, playlist)\n",
    "search_data = urlencode(\n",
    "    {\n",
    "        'q' : 'top hits of',\n",
    "        'type' : 'playlist',\n",
    "        'limit' : '50'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add to url to pass to get\n",
    "search_url = f'{endpoint}?{search_data}'\n",
    "\n",
    "# Get data for top hits playlists\n",
    "r = requests.get(search_url, headers = auth_header)\n",
    "\n",
    "# Get inital request\n",
    "# Convert returned items to dataframe\n",
    "playlist_df = pd.json_normalize(r.json()['playlists']['items'])\n",
    "\n",
    "# Subset playlist name reference data and only keep spotify playlists\n",
    "plist_df = playlist_df[\n",
    "    (playlist_df['owner.display_name'] == 'Spotify')\n",
    "    & (playlist_df['name'].str.contains('Top Hits'))\n",
    "][['id', 'name', 'owner.display_name', 'tracks.total', 'tracks.href']]\n",
    "\n",
    "\n",
    "# Playlist column names\n",
    "col_dict = {\n",
    "    'id' : 'playlist_id',\n",
    "    'name' : 'playlist_name',\n",
    "    'owner.display_name' : 'playlist_owner', \n",
    "    'tracks.total' : 'playlist_n_tracks',\n",
    "    'tracks.href' : 'tracks_href'\n",
    "}\n",
    "\n",
    "# Rename columns to\n",
    "plist_df = plist_df.rename(\n",
    "    columns = col_dict\n",
    ")\n",
    "\n",
    "# Extract year from playlist name\n",
    "plist_df['year'] = plist_df['playlist_name'].str.extract('(\\d{4})')\n",
    "\n",
    "# List of all years for which data are extracted\n",
    "yr_list = list(range(1980, 2025))\n",
    "yr_list = [str(y) for y in yr_list]\n",
    "\n",
    "# Initialize counter for for loop\n",
    "counter = 0\n",
    "\n",
    "# Loop through all years in yr list\n",
    "for y in yr_list:\n",
    "# while set(yr_list).issubset(set(plist_df['year'])) == False and counter <= 15:\n",
    "\n",
    "    \n",
    "    # Stopping conditions\n",
    "    if set(yr_list).issubset(set(plist_df['year'])) or counter > 15:\n",
    "        break\n",
    "\n",
    "    elif str(y) in list(plist_df['year']):\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(counter)\n",
    "        \n",
    "        # Search for top hits playlists; takes query (q) and type (artist, playlist)\n",
    "        search_data = urlencode(\n",
    "            {\n",
    "                'q' : 'top hits '+str(y),\n",
    "                'type' : 'playlist',\n",
    "                'limit' : '50'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add to url to pass to get\n",
    "        search_url = f'{endpoint}?{search_data}'\n",
    "\n",
    "        # Get data for top hits playlists\n",
    "        r = requests.get(search_url, headers = auth_header)\n",
    "\n",
    "        # Get inital request\n",
    "        # Convert returned items to dataframe\n",
    "        pl_df = pd.json_normalize(r.json()['playlists']['items'])\n",
    "\n",
    "        # Subset playlist name reference data and only keep spotify playlists\n",
    "        add_pdf = pl_df[\n",
    "            (pl_df['owner.display_name'] == 'Spotify')\n",
    "            & (pl_df['name'].str.contains('Top Hits'))\n",
    "        ][\n",
    "            ['id', 'name', 'owner.display_name', 'tracks.total', 'tracks.href']\n",
    "        ].rename(\n",
    "            columns = col_dict\n",
    "        )\n",
    "\n",
    "        # Get year\n",
    "        add_pdf['year'] = add_pdf['playlist_name'].str.extract('(\\d{4})')\n",
    "\n",
    "        # Join data frames\n",
    "        plist_df = pd.concat([plist_df, add_pdf])\n",
    "\n",
    "        # Iterate counter \n",
    "        counter += 1\n",
    "\n",
    "        # Wait a random amount of time\n",
    "        random_wait(t = 10)\n",
    "\n",
    "# Drop duplicates from plist and reset index\n",
    "plist_df = plist_df.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "# Print message to indicate that script has completed\n",
    "print('Script Executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca650b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Executed\n"
     ]
    }
   ],
   "source": [
    "# Store columns to be kept for tracks\n",
    "track_cols  = [\n",
    "    'track.id', 'track.name', 'track.popularity', 'track.available_markets', 'track.explicit',\n",
    "    'track.album.id', 'track.album.name', 'track.album.type', 'track.album.release_date', \n",
    "    'track.album.total_tracks', 'track.track_number', 'n_artists'\n",
    "]\n",
    "\n",
    "# Store columns for audio features\n",
    "audio_feature_cols = [\n",
    "    'id', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "    'liveness', 'valence', 'tempo', 'time_signature', 'duration_ms'\n",
    "]\n",
    "\n",
    "# Initialize counter\n",
    "counter = 0\n",
    "\n",
    "# Loop through playlist df and load track data and audio features\n",
    "for row in plist_df.iterrows():\n",
    "    \n",
    "    # Extract href, id, and number of tracks\n",
    "    href = row[1]['tracks_href']\n",
    "    pl_id = row[1]['playlist_id']\n",
    "    ntrack = row[1]['playlist_n_tracks']\n",
    "    \n",
    "    # Get track data\n",
    "    r2 = requests.get(href, headers = auth_header)\n",
    "\n",
    "    # Wait a random amount of time after api pull\n",
    "    random_wait(t = 5)\n",
    "\n",
    "    # Make track df from r2 requests\n",
    "    track_df = pd.json_normalize(r2.json()['items'])\n",
    "\n",
    "    # Number of artist\n",
    "    track_df['n_artists'] = track_df['track.artists'].str.len()\n",
    "\n",
    "    # Expand each artist to its own column\n",
    "    artist_df = pd.DataFrame(track_df['track.artists'].tolist(), index = track_df.index)\n",
    "\n",
    "    # Get number of artists\n",
    "    n_artists = artist_df.shape[1]\n",
    "\n",
    "    # Loop through columns and extract artist and artist id\n",
    "    for i in range(0, n_artists):\n",
    "        artist_df['artist'+str(i)+'_id'] = artist_df[i].str['id']\n",
    "        artist_df['artist'+str(i)+'_name'] = artist_df[i].str['name']\n",
    "\n",
    "    # Subset artists to only labeled columns\n",
    "    artist_df = artist_df.iloc[: , n_artists:]\n",
    "\n",
    "    # Merge artist and track data\n",
    "    df1 = track_df[track_cols].merge(artist_df, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "    # Replace periods with underscores\n",
    "    df1.columns = [c.replace('.', '_') for c in df1.columns]\n",
    "\n",
    "    # Count number of markets for track\n",
    "    df1['n_markets'] = df1['track_available_markets'].str.len()\n",
    "\n",
    "    # Add playlist id to df so it can be mapped to playlist_df\n",
    "    df1['playlist_id'] = pl_id\n",
    "\n",
    "    # Check how long playlist is, if longer than 100 then get two lists\n",
    "    if len(track_df) > 100:\n",
    "        # Get strings for all track ids\n",
    "        tid1 = ','.join(track_df.loc[0:100, 'track.id'])\n",
    "        tid2 = ','.join(track_df.loc[100:, 'track_id'])  \n",
    "\n",
    "        # Store urls for audio features\n",
    "        af_url1 = 'https://api.spotify.com/v1/audio-features?ids='+tid1\n",
    "        af_url2 = 'https://api.spotify.com/v1/audio-features?ids='+tid2\n",
    "\n",
    "        # Request audio features for first 100 tracks\n",
    "        r3 = requests.get(af_url1, headers = auth_header)\n",
    "\n",
    "        # Wait for random amount of time\n",
    "        random_wait(t = 5)\n",
    "\n",
    "        # Store in dataframe\n",
    "        af_df = pd.json_normalize(r3.json()['audio_features'])\n",
    "\n",
    "        # Request audio features for remaining tracks\n",
    "        r3 = requests.get(af_url2, headers = auth_header)\n",
    "\n",
    "        # Wait for random amount of time\n",
    "        random_wait(t = 5)\n",
    "\n",
    "        af_df = pd.concat([af_df, pd.json(normalize(r3.json()['audio_features']))])\n",
    "\n",
    "    else:\n",
    "        # Get string for all track ids\n",
    "        tid = ','.join(track_df['track.id'])\n",
    "\n",
    "        # Store urls for audio features\n",
    "        af_url = 'https://api.spotify.com/v1/audio-features?ids='+tid\n",
    "\n",
    "        # Request audio features\n",
    "        r3 = requests.get(af_url, headers = auth_header)\n",
    "\n",
    "        # Wait for random amount of time\n",
    "        random_wait(t = 5)    \n",
    "\n",
    "        # Store in dataframe\n",
    "        af_df = pd.json_normalize(r3.json()['audio_features'])\n",
    "\n",
    "    # Get only desired columns for audio features\n",
    "    af_df = af_df[audio_feature_cols].rename(columns = {'id': 'track_id'})\n",
    "\n",
    "    # Merge audio features\n",
    "    df1 = df1.merge(af_df, how = 'left', on = 'track_id')    \n",
    "\n",
    "    # If counter is 0, make final df as copy of df1 else concatenate the two\n",
    "    if counter == 0:\n",
    "        df = df1.copy()\n",
    "    else:\n",
    "        df = pd.concat([df, df1])\n",
    "        \n",
    "    counter += 1\n",
    "        \n",
    "# Merge df to playlist\n",
    "df = plist_df.merge(df, how = 'inner', on = ['playlist_id'])\n",
    "\n",
    "# Print message to indicate script has run\n",
    "print('Script Executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e114553",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove \"This Is Top Hits 2024\" which seems to be bogus\n",
    "dfs = df[df['year'] != '2024']\n",
    "\n",
    "# Save to csv\n",
    "dfs.to_csv('SpotifyTopHits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621559ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c21d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc0522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
